import os
import chromadb
import json # Added for RAG source formatting

from llama_index.core.tools import FunctionTool, QueryEngineTool
from llama_index.core.vector_stores import VectorStoreInfo
from llama_index.vector_stores.chroma import ChromaVectorStore
from llama_index.readers.web import BeautifulSoupWebReader
from llama_index.readers.semanticscholar import SemanticScholarReader
from llama_index.tools.wikipedia import WikipediaToolSpec
from llama_index.tools.tavily_research import TavilyToolSpec
from llama_index.tools.duckduckgo import DuckDuckGoSearchToolSpec # Corrected import name if needed, ensure library provides this
from llama_index.core import VectorStoreIndex, StorageContext
from llama_index.core.agent import FunctionCallingAgentWorker
from llama_index.core import Settings
from llama_index.tools.code_interpreter import CodeInterpreterToolSpec # Import the tool spec#
# from llama_index.tools.azure_code_interpreter import AzureCodeInterpreterToolSpec as CodeInterpreterToolSpec

# Ensure API keys are set as environment variables
# os.environ["TAVILY_API_KEY"] = "YOUR_TAVILY_API_KEY"
# os.environ["GOOGLE_API_KEY"] = "YOUR_GOOGLE_API_KEY"

# Directory where files generated by code interpreter should be accessible by the UI
UI_ACCESSIBLE_WORKSPACE = "./code_interpreter_ws"
os.makedirs(UI_ACCESSIBLE_WORKSPACE, exist_ok=True)


# --- Individual Tool Initializations ---

def get_duckduckgo_tool():
    """Initializes the DuckDuckGo search tool."""
    try:
        return DuckDuckGoSearchToolSpec().to_tool_list()[0]
    except NameError:
        print("Error: DuckDuckGoSearchToolSpec not found. Trying DuckDuckGoToolSpec.")
        try:
            from llama_index.tools.duckduckgo import DuckDuckGoToolSpec
            return DuckDuckGoToolSpec().to_tool_list()[0]
        except Exception as e_fallback:
            print(f"Error initializing DuckDuckGo Tool (fallback failed): {e_fallback}")
            return None
    except Exception as e:
        print(f"Error initializing DuckDuckGo Tool: {e}")
        return None

def get_tavily_tool():
    """Initializes the Tavily search tool."""
    tavily_api_key = os.getenv("TAVILY_API_KEY")
    if not tavily_api_key:
        print("Warning: TAVILY_API_KEY not found in environment variables.")
        return None
    try:
        return TavilyToolSpec(api_key=tavily_api_key).to_tool_list()[0]
    except Exception as e:
        print(f"Error initializing Tavily Tool: {e}")
        return None

def get_wikipedia_tool():
    """Initializes the Wikipedia tool."""
    try:
        return WikipediaToolSpec().to_tool_list()[0]
    except Exception as e:
        print(f"Error initializing Wikipedia Tool: {e}")
        return None

def get_semantic_scholar_tool_for_agent():
    """
    Initializes the Semantic Scholar tool.
    Returns a list containing the tool, suitable for an agent.
    """
    try:
        ss_reader = SemanticScholarReader()
        tool = FunctionTool.from_defaults(
            fn=lambda query: ss_reader.load_data(query=query, limit=5), # Load 5 papers
            name="semantic_scholar_search",
            description="Searches Semantic Scholar for academic papers based on a query.",
        )
        return [tool] if tool else []
    except Exception as e:
        print(f"Error initializing Semantic Scholar Tool: {e}")
        return []

def get_web_scraper_tool_for_agent():
    """
    Initializes the Web Scraper tool.
    Returns a list containing the tool, suitable for an agent.
    """
    try:
        loader = BeautifulSoupWebReader()
        tool = FunctionTool.from_defaults(
            fn=lambda url: loader.load_data(urls=[url]),
            name="web_scraper",
            description="Scrapes content from a given URL. Expects a single URL as input.",
        )
        return [tool] if tool else []
    except Exception as e:
        print(f"Error initializing Web Scraper Tool: {e}")
        return []

def get_rag_tool_for_agent(db_path="./ragdb", collection_name="resources"):
    """Initializes the RAG query tool using ChromaDB."""
    try:
        # Initialize ChromaDB client
        # Use the provided db_path which should be the path to the chromadb directory
        db = chromadb.PersistentClient(path=db_path)

        # Check if collection exists before trying to get it
        try:
            chroma_collection = db.get_collection(collection_name)
            print(f"Connected to ChromaDB collection. Contains {chroma_collection.count()} documents.")
        except Exception as e:
             # Handle case where collection does not exist
             print(f"Error accessing ChromaDB collection '{collection_name}' at path '{db_path}': {e}")
             print("Please ensure you have run ragdb/make_rag.py to create the database.")
             # Return a dummy tool indicating the collection is missing
             return FunctionTool.from_defaults(
                fn=lambda *args, **kwargs: f"Error: The local knowledge base (RAG) collection '{collection_name}' was not found at '{db_path}'. Please ensure it has been created.",
                name="rag_dissertation_retriever",
                description="The local dissertation knowledge base is currently unavailable because the collection was not found."
            )


        # Initialize vector store with HuggingFace embeddings
        vector_store = ChromaVectorStore(chroma_collection=chroma_collection)
        storage_context = StorageContext.from_defaults(vector_store=vector_store)

        # Create index with HuggingFace embeddings (redundant if set globally, but harmless)
        # Ensure Settings.embed_model is set before this point, ideally in agent.py or app.py
        # Settings.embed_model = HuggingFaceEmbedding(model_name="BAAI/bge-small-en-v1.5") # This should be set globally

        # Check if collection has documents
        if chroma_collection.count() > 0: # More reliable check
             # Explicitly pass the global LLM to the query engine to avoid OpenAI fallback
             # Ensure Settings.llm is set before this point, ideally in agent.py or app.py
             # Need to create the index first before getting the query engine
             index = VectorStoreIndex.from_vector_store(
                 vector_store=vector_store,
                 storage_context=storage_context,
                 embed_model=Settings.embed_model # Use the globally set embed model
             )
             query_engine = index.as_query_engine(llm=Settings.llm) # Use the globally set LLM

             # Define a simple function to wrap the query engine call
             def execute_rag_query(input: str):
                 """Executes a query against the RAG engine and returns the text response."""
                 try:
                     response_obj = query_engine.query(input)
                     text_response = str(response_obj.response) # The LLM-generated text summary

                     sources_info_parts = []
                     citation_counter = 1
                     assigned_pdf_citations = {} # Maps file_path to citation_number for uniqueness within this call

                     if response_obj.source_nodes:
                         for source_node in response_obj.source_nodes:
                             metadata = source_node.node.metadata
                             node_text_snippet = source_node.node.get_text()[:100] # For context

                             if 'file_path' in metadata:
                                 file_path = metadata['file_path']
                                 file_name = os.path.basename(file_path)
                                 
                                 current_citation_number = None
                                 if file_path not in assigned_pdf_citations:
                                     assigned_pdf_citations[file_path] = citation_counter
                                     current_citation_number = citation_counter
                                     citation_counter += 1
                                 else:
                                     current_citation_number = assigned_pdf_citations[file_path]
                                 
                                 source_data = {
                                     "type": "pdf", 
                                     "name": file_name, 
                                     "path": file_path, 
                                     "snippet": node_text_snippet + "...",
                                     "citation_number": current_citation_number # Add citation number
                                 }
                                 sources_info_parts.append(f"---RAG_SOURCE---{json.dumps(source_data)}")
                             elif 'url' in metadata: # Check for 'url' for web sources
                                 url = metadata['url']
                                 title = metadata.get('title', url) # Use title if available, else URL
                                 source_data = {"type": "web", "url": url, "title": title, "snippet": node_text_snippet + "..."}
                                 # No citation number for web links in this iteration, can be added if needed
                                 sources_info_parts.append(f"---RAG_SOURCE---{json.dumps(source_data)}")
                             # Add more conditions here if other metadata keys indicate different source types

                     # Append source markers to the text response
                     if sources_info_parts:
                         return text_response + "\n" + "\n".join(sources_info_parts)
                     else:
                         return text_response

                 except Exception as e:
                     print(f"Error during RAG query execution: {e}")
                     return f"Error querying the knowledge base: {e}"

             # Wrap the simple function with FunctionTool
             return FunctionTool.from_defaults(
                 fn=execute_rag_query,
                 name="rag_dissertation_retriever",
                 description=(
                     f"Retrieves relevant information from the local dissertation knowledge base stored in '{collection_name}'. "
                     "Use this for specific institutional knowledge or previously saved research. "
                     "The tool's output will include the textual answer and may be followed by structured references "
                     "(e.g., to PDF files or web URLs) using '---RAG_SOURCE---' markers. "
                     "For PDF sources, the structured reference will include a 'citation_number'. "
                     "When you use information from a PDF source in your response, you MUST append its citation number "
                     "in brackets (e.g., '[1]', '[2]') to the relevant sentence or claim. "
                     "The query to the knowledge base should be provided as the 'input' string argument."
                 ),
             )
        else:
            print(f"Warning: No documents found in ChromaDB collection '{collection_name}' at path '{db_path}'. RAG tool disabled.")
            # Return a dummy tool or None if the index is empty
            return FunctionTool.from_defaults(
                fn=lambda *args, **kwargs: f"Error: The local knowledge base (RAG) collection '{collection_name}' is empty.",
                name="rag_dissertation_retriever",
                description="The local dissertation knowledge base is currently empty."
            )

    except Exception as e:
        error_message = f"Error initializing RAG tool: {e}" # Corrected indentation for the 'else' block as well
        print(error_message)
        # Return a dummy tool or None in case of error
        # Capture the error message in the lambda's default argument
        return FunctionTool.from_defaults(
            fn=lambda *args, msg=error_message, **kwargs: msg,
            name="rag_dissertation_retriever",
            description="The local dissertation knowledge base is currently unavailable due to an error during initialization."
        )


# --- Tool Collections for Specialized Agents ---

def get_search_tools():
    """Initializes and returns a list of search-related tools."""
    tools = []
    ddg_tool = get_duckduckgo_tool()
    tavily_tool = get_tavily_tool()
    wiki_tool = get_wikipedia_tool()

    if ddg_tool: tools.append(ddg_tool)
    if tavily_tool: tools.append(tavily_tool)
    if wiki_tool: tools.append(wiki_tool)
    
    print(f"Initialized {len(tools)} search tools.")
    return tools

# Note: get_semantic_scholar_tool_for_agent, get_web_scraper_tool_for_agent, 
# and get_rag_tool_for_agent already return lists of tools (or a single tool in a list).

# --- Code Interpreter Tool Setup ---

def get_coder_tools():
    """
    Initializes the Code Interpreter tool, configured to use the shared workspace.
    Returns the original tool spec's tool list.
    """
    try:
        # Initialize the standard tool spec
        # local_workdir argument removed as it's not accepted by the constructor.
        # The tool will likely use a default working directory.
        # The Coder Agent's prompt guides it to save files in UI_ACCESSIBLE_WORKSPACE.
        code_spec = CodeInterpreterToolSpec()
        original_tools = code_spec.to_tool_list()

        if not original_tools:
            print("Warning: CodeInterpreterToolSpec returned no tools.")
            return []

        print(f"Initialized Code Interpreter Tool(s) for Coder Agent: {[t.metadata.name for t in original_tools]}")
        return original_tools

    except Exception as e:
        print(f"Error initializing Code Interpreter Tool for Coder Agent: {e}. Code execution will be unavailable.")
        return []

# if __name__ == '__main__':
#     # Example usage (for testing)
#     # Ensure UI_ACCESSIBLE_WORKSPACE exists for testing code interpreter
#     os.makedirs(UI_ACCESSIBLE_WORKSPACE, exist_ok=True)
#     from dotenv import load_dotenv
#     # Need to import Settings here for the test block to work
#     from llama_index.core import Settings
#     from llama_index.llms.gemini import Gemini
#     from llama_index.embeddings.huggingface import HuggingFaceEmbedding

#     load_dotenv()

#     # Initialize Settings for testing purposes
#     google_api_key = os.getenv("GOOGLE_API_KEY")
#     if not google_api_key:
#         print("Warning: GOOGLE_API_KEY not found for testing.")
#         # Provide dummy settings if key is missing, or skip test
#         Settings.llm = None # Or a dummy LLM
#         Settings.embed_model = None # Or a dummy embedding
#     else:
#         Settings.llm = Gemini(model_name="models/gemini-1.5-flash-latest", api_key=google_api_key) # Use a test model
#         Settings.embed_model = HuggingFaceEmbedding(model_name="BAAI/bge-small-en-v1.5")


#     try:
#         test_db_path = os.path.abspath(os.path.join(os.path.dirname(__file__), '..', 'ragdb', 'chromadb'))
#         print(f"Attempting to initialize RAG tool with test DB path: {test_db_path}")
#         rag_tools_list = get_rag_tool_for_agent(db_path=test_db_path)
#         if rag_tools_list:
#             rag_tool = rag_tools_list[0]
#             print(f"RAG Tool: {rag_tool.metadata.name} - {rag_tool.metadata.description[:60]}...")
#             # Further testing of rag_tool.fn() or rag_tool.query_engine if applicable
#         else:
#             print("RAG tool failed to initialize.")

#         print("\nInitializing search tools...")
#         search_tools_list = get_search_tools()
#         for tool in search_tools_list:
#             print(f"- Search Tool: {tool.metadata.name}")

#         print("\nInitializing literature reviewer tool...")
#         lit_tools_list = get_semantic_scholar_tool_for_agent()
#         if lit_tools_list:
#             print(f"- Lit Review Tool: {lit_tools_list[0].metadata.name}")
        
#         print("\nInitializing scraper tool...")
#         scraper_tools_list = get_web_scraper_tool_for_agent()
#         if scraper_tools_list:
#             print(f"- Scraper Tool: {scraper_tools_list[0].metadata.name}")

#         print("\nInitializing coder tools...")
#         coder_tools_list = get_coder_tools()
#         for tool in coder_tools_list:
#             print(f"- Coder Tool: {tool.metadata.name}")
#         # Example: Test coder tool if it's a FunctionTool that can be called directly
#         # if coder_tools_list and hasattr(coder_tools_list[0], 'fn'):
#         #     try:
#         #         print("\nAttempting Coder Tool Test (e.g., simple print)...")
#         #         output = coder_tools_list[0].fn("print('Hello from Coder Agent Test')")
#         #         print("Coder Tool Test Output:", output) # Output structure depends on CodeInterpreterOutput
#         #     except Exception as code_e:
#         #         print(f"Error during Coder tool test: {code_e}")


#     except Exception as e:
#         print(f"Error during tools testing: {e}")
