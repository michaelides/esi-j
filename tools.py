import os
# import chromadb # Removed chromadb
import json # Added for RAG source formatting

from llama_index.core.tools import FunctionTool, QueryEngineTool
# from llama_index.core.vector_stores import VectorStoreInfo # Not used directly now
# from llama_index.vector_stores.chroma import ChromaVectorStore # Removed chromadb
from llama_index.core.vector_stores import SimpleVectorStore # Added for type hinting if needed
from llama_index.readers.web import BeautifulSoupWebReader
from llama_index.readers.semanticscholar import SemanticScholarReader
from llama_index.tools.wikipedia import WikipediaToolSpec
from llama_index.tools.tavily_research import TavilyToolSpec
from llama_index.tools.duckduckgo import DuckDuckGoSearchToolSpec # Corrected import name if needed, ensure library provides this
from llama_index.core import VectorStoreIndex, StorageContext, load_index_from_storage # Added load_index_from_storage
from llama_index.core.agent import FunctionCallingAgentWorker
from llama_index.core import Settings
from llama_index.tools.code_interpreter import CodeInterpreterToolSpec
# from llama_index.core.tools.local_code_interpreter import LocalCodeInterpreter # Removed problematic import
# from llama_index.tools.azure_code_interpreter import AzureCodeInterpreterToolSpec as CodeInterpreterToolSpec

# Ensure API keys are set as environment variables
# os.environ["TAVILY_API_KEY"] = "YOUR_TAVILY_API_KEY"
# os.environ["GOOGLE_API_KEY"] = "YOUR_GOOGLE_API_KEY"

# Directory where files generated by code interpreter should be accessible by the UI
# Make it an absolute path
UI_ACCESSIBLE_WORKSPACE = os.path.abspath("./code_interpreter_ws")
os.makedirs(UI_ACCESSIBLE_WORKSPACE, exist_ok=True)


# --- Individual Tool Initializations ---

def get_duckduckgo_tool():
    """Initializes the DuckDuckGo search tool."""
    try:
        return DuckDuckGoSearchToolSpec().to_tool_list()[0]
    except NameError:
        print("Error: DuckDuckGoSearchToolSpec not found. Trying DuckDuckGoToolSpec.")
        try:
            from llama_index.tools.duckduckgo import DuckDuckGoToolSpec
            return DuckDuckGoToolSpec().to_tool_list()[0]
        except Exception as e_fallback:
            print(f"Error initializing DuckDuckGo Tool (fallback failed): {e_fallback}")
            return None
    except Exception as e:
        print(f"Error initializing DuckDuckGo Tool: {e}")
        return None

def get_tavily_tool():
    """Initializes the Tavily search tool."""
    tavily_api_key = os.getenv("TAVILY_API_KEY")
    if not tavily_api_key:
        print("Warning: TAVILY_API_KEY not found in environment variables.")
        return None
    try:
        return TavilyToolSpec(api_key=tavily_api_key).to_tool_list()[0]
    except Exception as e:
        print(f"Error initializing Tavily Tool: {e}")
        return None

def get_wikipedia_tool():
    """Initializes the Wikipedia tool."""
    try:
        return WikipediaToolSpec().to_tool_list()[0]
    except Exception as e:
        print(f"Error initializing Wikipedia Tool: {e}")
        return None

def get_semantic_scholar_tool_for_agent():
    """
    Initializes the Semantic Scholar tool.
    Returns a list containing the tool, suitable for an agent.
    """
    try:
        ss_reader = SemanticScholarReader()
        tool = FunctionTool.from_defaults(
            fn=lambda query: ss_reader.load_data(query=query, limit=5), # Load 5 papers
            name="semantic_scholar_search",
            description="Searches Semantic Scholar for academic papers based on a query.",
        )
        return [tool] if tool else []
    except Exception as e:
        print(f"Error initializing Semantic Scholar Tool: {e}")
        return []

def get_web_scraper_tool_for_agent():
    """
    Initializes the Web Scraper tool.
    Returns a list containing the tool, suitable for an agent.
    """
    try:
        loader = BeautifulSoupWebReader()
        tool = FunctionTool.from_defaults(
            fn=lambda url: loader.load_data(urls=[url]),
            name="web_scraper",
            description="Scrapes content from a given URL. Expects a single URL as input.",
        )
        return [tool] if tool else []
    except Exception as e:
        print(f"Error initializing Web Scraper Tool: {e}")
        return []

# Note: collection_name is no longer needed for SimpleVectorStore
def get_rag_tool_for_agent(db_path="./ragdb/simple_vector_store"):
    """Initializes the RAG query tool using a persisted SimpleVectorStore."""
    persist_dir = db_path # db_path now directly points to the persistence directory
    print(f"Attempting to load RAG index from persistence directory: {persist_dir}")

    # Check if the persistence directory exists
    if not os.path.exists(persist_dir) or not os.listdir(persist_dir): # Check if dir exists and is not empty
        print(f"Error: Persistence directory '{persist_dir}' not found or is empty.")
        print("Please run 'python ragdb/make_rag.py' to build the local knowledge base.")
        # Return a dummy tool indicating the store is missing
        return FunctionTool.from_defaults(
            fn=lambda *args, **kwargs: f"Error: The local knowledge base was not found at '{persist_dir}'. Please ensure it has been created by running 'python ragdb/make_rag.py'.",
            name="rag_dissertation_retriever",
            description="The local dissertation knowledge base is currently unavailable because it has not been built or loaded."
        )

    try:
        # Load the index from the persisted directory
        # Ensure Settings.embed_model and Settings.llm are set globally before this
        print("Loading index from storage...")
        storage_context = StorageContext.from_defaults(persist_dir=persist_dir)
        # SimpleVectorStore is loaded automatically within the storage context
        # We need the embed_model to potentially reconstruct parts of the index if needed by LlamaIndex
        index = load_index_from_storage(storage_context, embed_model=Settings.embed_model)
        print("Successfully loaded index from storage.")

        # Create a query engine from the loaded index
        # Ensure Settings.llm is set globally
        query_engine = index.as_query_engine(llm=Settings.llm)
        print("RAG query engine created.")

        # Define a simple function to wrap the query engine call
        def execute_rag_query(input: str):
                 """Executes a query against the RAG engine and returns the text response."""
                 try:
                     response_obj = query_engine.query(input)
                     text_response = str(response_obj.response) # The LLM-generated text summary

                     sources_info_parts = []
                     citation_counter = 1
                     assigned_pdf_citations = {} # Maps file_path to citation_number for uniqueness within this call

                     if response_obj.source_nodes:
                         for source_node in response_obj.source_nodes:
                             metadata = source_node.node.metadata
                             node_text_snippet = source_node.node.get_text()[:100] # For context

                             if 'file_path' in metadata:
                                 file_path = metadata['file_path']
                                 file_name = os.path.basename(file_path)
                                 
                                 current_citation_number = None
                                 if file_path not in assigned_pdf_citations:
                                     assigned_pdf_citations[file_path] = citation_counter
                                     current_citation_number = citation_counter
                                     citation_counter += 1
                                 else:
                                     current_citation_number = assigned_pdf_citations[file_path]
                                 
                                 source_data = {
                                     "type": "pdf", 
                                     "name": file_name, 
                                     "path": file_path, 
                                     "snippet": node_text_snippet + "...",
                                     "citation_number": current_citation_number # Add citation number
                                 }
                                 sources_info_parts.append(f"---RAG_SOURCE---{json.dumps(source_data)}")
                             elif 'url' in metadata: # Check for 'url' for web sources
                                 url = metadata['url']
                                 title = metadata.get('title', url) # Use title if available, else URL
                                 source_data = {"type": "web", "url": url, "title": title, "snippet": node_text_snippet + "..."}
                                 # No citation number for web links in this iteration, can be added if needed
                                 sources_info_parts.append(f"---RAG_SOURCE---{json.dumps(source_data)}")
                             # Add more conditions here if other metadata keys indicate different source types

                     # Append source markers to the text response
                     if sources_info_parts:
                         return text_response + "\n" + "\n".join(sources_info_parts)
                     else:
                         return text_response

                 except Exception as e:
                     print(f"Error during RAG query execution: {e}")
                     return f"Error querying the knowledge base: {e}"

             # Wrap the simple function with FunctionTool
             return FunctionTool.from_defaults(
                 fn=execute_rag_query,
                 name="rag_dissertation_retriever",
                 description=(
                     f"Retrieves relevant information from the local dissertation knowledge base (persisted at '{persist_dir}'). "
                     "Use this for specific institutional knowledge or previously saved research. "
                     "The tool's output will include the textual answer and may be followed by structured references "
                     "(e.g., to PDF files or web URLs) using '---RAG_SOURCE---' markers. "
                     "For PDF sources, the structured reference will include a 'citation_number'. "
                     "When you use information from a PDF source in your response, you MUST append its citation number "
                     "in brackets (e.g., '[1]', '[2]') to the relevant sentence or claim. "
                     "The query to the knowledge base should be provided as the 'input' string argument."
                 ),
             )
        # The check for empty index is implicitly handled by the loading process.
        # If loading succeeds, we assume the index is usable.

    except Exception as e:
        error_message = f"Error initializing or loading RAG tool from '{persist_dir}': {e}"
        print(error_message)
        # Return a dummy tool in case of loading error
        # Capture the error message in the lambda's default argument
        return FunctionTool.from_defaults(
            fn=lambda *args, msg=error_message, **kwargs: msg,
            name="rag_dissertation_retriever",
            description="The local dissertation knowledge base is currently unavailable due to an error during initialization."
        )


# --- Tool Collections for Specialized Agents ---

def get_search_tools():
    """Initializes and returns a list of search-related tools."""
    tools = []
    ddg_tool = get_duckduckgo_tool()
    tavily_tool = get_tavily_tool()
    wiki_tool = get_wikipedia_tool()

    if ddg_tool: tools.append(ddg_tool)
    if tavily_tool: tools.append(tavily_tool)
    if wiki_tool: tools.append(wiki_tool)
    
    print(f"Initialized {len(tools)} search tools.")
    return tools

# Note: get_semantic_scholar_tool_for_agent, get_web_scraper_tool_for_agent, 
# and get_rag_tool_for_agent already return lists of tools (or a single tool in a list).

# --- Code Interpreter Tool Setup ---

def get_coder_tools():
    """
    Initializes the Code Interpreter tool, configured to use the shared workspace.
    Returns the original tool spec's tool list.
    """
    try:
        # Initialize CodeInterpreterToolSpec
        code_spec = CodeInterpreterToolSpec()

        # Attempt to set the work_dir of the underlying code_interpreter
        if hasattr(code_spec, 'code_interpreter') and code_spec.code_interpreter is not None:
            if hasattr(code_spec.code_interpreter, 'work_dir'):
                print(f"Attempting to set work_dir for code_interpreter to: {UI_ACCESSIBLE_WORKSPACE}")
                code_spec.code_interpreter.work_dir = UI_ACCESSIBLE_WORKSPACE
                # Verify if it was set (for debugging)
                print(f"Code interpreter work_dir is now: {getattr(code_spec.code_interpreter, 'work_dir', 'N/A')}")
            else:
                print("Warning: code_spec.code_interpreter does not have a 'work_dir' attribute.")
        else:
            print("Warning: code_spec.code_interpreter is not available. Cannot set work_dir. Files may be saved to a temporary location.")

        original_tools = code_spec.to_tool_list()

        if not original_tools:
            print("Warning: CodeInterpreterToolSpec returned no tools.")
            return []

        print(f"Initialized Code Interpreter Tool(s) for Coder Agent: {[t.metadata.name for t in original_tools]}")
        return original_tools

    except Exception as e:
        print(f"Error initializing Code Interpreter Tool for Coder Agent: {e}. Code execution will be unavailable.")
        return []

# if __name__ == '__main__':
#     # Example usage (for testing)
#     # Ensure UI_ACCESSIBLE_WORKSPACE exists for testing code interpreter
#     os.makedirs(UI_ACCESSIBLE_WORKSPACE, exist_ok=True)
#     from dotenv import load_dotenv
#     # Need to import Settings here for the test block to work
#     from llama_index.core import Settings
#     from llama_index.llms.gemini import Gemini
#     from llama_index.embeddings.huggingface import HuggingFaceEmbedding

#     load_dotenv()

#     # Initialize Settings for testing purposes
#     google_api_key = os.getenv("GOOGLE_API_KEY")
#     if not google_api_key:
#         print("Warning: GOOGLE_API_KEY not found for testing.")
#         # Provide dummy settings if key is missing, or skip test
#         Settings.llm = None # Or a dummy LLM
#         Settings.embed_model = None # Or a dummy embedding
#     else:
#         Settings.llm = Gemini(model_name="models/gemini-1.5-flash-latest", api_key=google_api_key) # Use a test model
#         Settings.embed_model = HuggingFaceEmbedding(model_name="BAAI/bge-small-en-v1.5")


#     try:
#         # Update test path to point to the simple vector store directory
#         test_db_path = os.path.abspath(os.path.join(os.path.dirname(__file__), '..', 'ragdb', 'simple_vector_store'))
#         print(f"Attempting to initialize RAG tool with test DB path: {test_db_path}")
#         # get_rag_tool_for_agent now returns a single tool, not a list
#         rag_tool = get_rag_tool_for_agent(db_path=test_db_path)
#         if rag_tool:
#             # rag_tool = rag_tools_list[0] # No longer needed
#             print(f"RAG Tool: {rag_tool.metadata.name} - {rag_tool.metadata.description[:60]}...")
#             # Further testing of rag_tool.fn() or rag_tool.query_engine if applicable
#         else:
#             print("RAG tool failed to initialize.")

#         print("\nInitializing search tools...")
#         search_tools_list = get_search_tools()
#         for tool in search_tools_list:
#             print(f"- Search Tool: {tool.metadata.name}")

#         print("\nInitializing literature reviewer tool...")
#         lit_tools_list = get_semantic_scholar_tool_for_agent()
#         if lit_tools_list:
#             print(f"- Lit Review Tool: {lit_tools_list[0].metadata.name}")
        
#         print("\nInitializing scraper tool...")
#         scraper_tools_list = get_web_scraper_tool_for_agent()
#         if scraper_tools_list:
#             print(f"- Scraper Tool: {scraper_tools_list[0].metadata.name}")

#         print("\nInitializing coder tools...")
#         coder_tools_list = get_coder_tools()
#         for tool in coder_tools_list:
#             print(f"- Coder Tool: {tool.metadata.name}")
#         # Example: Test coder tool if it's a FunctionTool that can be called directly
#         # if coder_tools_list and hasattr(coder_tools_list[0], 'fn'):
#         #     try:
#         #         print("\nAttempting Coder Tool Test (e.g., simple print)...")
#         #         output = coder_tools_list[0].fn("print('Hello from Coder Agent Test')")
#         #         print("Coder Tool Test Output:", output) # Output structure depends on CodeInterpreterOutput
#         #     except Exception as code_e:
#         #         print(f"Error during Coder tool test: {code_e}")


#     except Exception as e:
#         print(f"Error during tools testing: {e}")
